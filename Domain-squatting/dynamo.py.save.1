#!/usr/bin/python3
# Python Script to insert csv records in dynamodb table.
from __future__ import print_function  # Python 2/3 compatibility
from __future__ import division  # Python 2/3 compatiblity for integer division
import argparse
import boto3
from csv import reader
import csv
import time
from datetime import datetime
import codecs
import sys
import os
import json

s3 = boto3.resource('s3')
dynamodb = boto3.resource('dynamodb')


def write_log(op):

    # Current time - dd/mm/YY H:M:S
    now = datetime.now()
    dt_string = now.strftime("%d/%m/%Y %H:%M")

    with open("
dynamo.log", "a") as f_log:
        my_row = op + ": " + dt_string + "\n"
        f_log.write(my_row)
    f_log.close()


def convert_csv(csv_file):
    
    # Current time - dd/mm/YY H:M:S
    now = datetime.now()
    dt_string = now.strftime("%Y-%m-%d")

    f_dom = open("domain-names.txt", "r")


    with open(csv_file, 'w') as f_csv:
        writer = csv.writer(f_csv)
        writer.writerow(('domain', 'reg_date'))
    
        for domain in f_dom:
            domain = domain.replace("\n", "")
            my_row = domain + "," + dt_string + "\n"
            f_csv.write(my_row)

    f_csv.close()
    time.sleep(1)
    
    return True


def write_to_dynamo(rows):

    try:
        table = dynamodb.Table("dev_opensquat_domains")
    except:
        print("Error loading DynamoDB table. Check if table was created correctly and environment variable.")

    try:
        with table.batch_writer() as batch:
             for i in range(len(rows)):
                batch.put_item(
                    Item=rows[i]
             )
    except:
        print("Error executing batch_writer")


def export_dynamodb(csv_file):

    # dynamodb and table initialization
    endpointUrl = "https://dynamodb.eu-west-1.amazonaws.com"
    dynamodb = boto3.resource('dynamodb', region_name="eu-west-1", endpoint_url=endpointUrl)
    table = dynamodb.Table("dev_opensquat_domains")
    writeRate = 100
    delimiter = ","

    batch_size = 100
    batch = []

    f_csv = open(csv_file)

    #DictReader is a generator; not stored in memory
    for row in csv.DictReader(f_csv):
       if len(batch) >= batch_size:
          write_to_dynamo(batch)
          batch.clear()

       batch.append(row)

    if batch:
       write_to_dynamo(batch)



csv_file = "domains.csv"

write_log("start")

if (convert_csv(csv_file)):
    export_dynamodb(csv_file)
    write_log("finish")

